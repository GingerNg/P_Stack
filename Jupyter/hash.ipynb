{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Hash<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>局部敏感hash（local sensitive hash）<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### simhash\n",
    "- https://blog.csdn.net/madujin/article/details/53152619\n",
    "- https://blog.csdn.net/heiyeshuwu/article/details/69706414\n",
    "- https://www.cnblogs.com/csj007523/p/7773027.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.analyse\n",
    "import numpy as np\n",
    "import jieba.posseg as pseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18446744073709551616"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow(2,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nosie(line):\n",
    "    filter_pool = [\"。\",\".\",\";\",\"，\",\"|\",\"&\",\"%\",\"-\",\"=\",\"\\\"\",\"\\'\",\"“\",\"”\",\"(\",\")\",\"（\",\"）\",\":\",\"：\",\"\\n\"]\n",
    "    # chinese_character = [\"一\", \"二\", \"三\", \"四\", \"五\", \"六\", \"七\", \"八\", \"九\", \"十\", \"零\",\"○\"]\n",
    "    # alb_number = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\"]\n",
    "    # for c in chinese_character:\n",
    "    #     line = line.replace(c, \"\")\n",
    "    # for c in alb_number:\n",
    "    #     line = line.replace(c, \"\")\n",
    "    for c in filter_pool:\n",
    "        line = line.replace(c, \"\")\n",
    "    return line.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_hash(source):\n",
    "    if source == \"\":\n",
    "        return 0\n",
    "    else:\n",
    "        x = ord(source[0]) << 7\n",
    "        m = 1000003\n",
    "        mask = 2 ** 128 - 1\n",
    "        for c in source:\n",
    "            x = ((x * m) ^ ord(c)) & mask\n",
    "        x ^= len(source)\n",
    "        if x == -1:\n",
    "            x = -2\n",
    "        x = bin(x).replace('0b', '').zfill(64)[-64:]\n",
    "        # print(source, x)\n",
    "\n",
    "        return str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_title = [\"原创\",\"转载\",'音频','视频','图片']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywords2hash(keyWord):\n",
    "    keyList = []\n",
    "    # print(keyWord)\n",
    "    for feature, weight in keyWord:\n",
    "        weight = int(weight * 20)\n",
    "        feature = string_hash(feature)\n",
    "        temp = []\n",
    "        for i in feature:\n",
    "            if (i == '1'):\n",
    "                temp.append(weight)\n",
    "            else:\n",
    "                temp.append(-weight)\n",
    "        # print(temp)\n",
    "        keyList.append(temp)\n",
    "    list1 = np.sum(np.array(keyList), axis=0)\n",
    "    if (keyList == []):  # 编码读不出来\n",
    "        return '00'\n",
    "    simhash = ''\n",
    "    for i in list1:\n",
    "        if (i > 0):\n",
    "            simhash = simhash + '1'\n",
    "        else:\n",
    "            simhash = simhash + '0'\n",
    "    return simhash,keyWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_distribution(l:int):\n",
    "    \"\"\"\n",
    "    权重分配\n",
    "    越靠前权重越高，总权重为1\n",
    "    \"\"\"\n",
    "    s = [1]\n",
    "    for i in range(1,l):\n",
    "        c = s[i-1]\n",
    "        s[i-1] = c/2\n",
    "        s.append(c/2)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word(object):\n",
    "    def __init__(self, token, pos, weight=0):\n",
    "        self.token = token\n",
    "        self.pos = pos\n",
    "        self.weight = weight\n",
    "\n",
    "filter_pos = [\"c\",\"f\",\"uj\",\"r\",\"x\",\"p\"]\n",
    "keep_pos = ['ns', 'n', 'nz','nrt','vn', 'v','t','tg','tg','qt','mq','m','nr','nt',\"vn\",'q',\"eng\"]\n",
    "def filter_by_pos(seg_list,filter_type=0):\n",
    "    if filter_type == 0:\n",
    "        return [f.token for f in seg_list if f.pos not in filter_pos]\n",
    "    else:\n",
    "        return [f.token for f in seg_list if f.pos in keep_pos]\n",
    "    \n",
    "def get_simhash_shorttext(short_content):\n",
    "    for s in stops_title:\n",
    "        short_content = short_content.replace(s,\"\")\n",
    "    # segs = jieba.lcut(short_content)\n",
    "    words = [Word(word, tag) for word, tag in pseg.cut(short_content)]\n",
    "#     print(words)\n",
    "    seg_list = filter_by_pos(seg_list=words, filter_type=1)\n",
    "    len_segs = len(seg_list)\n",
    "    ws = weight_distribution(len_segs)\n",
    "    # for word, tag in pseg.cut(short_content):\n",
    "    #     print(word, tag)\n",
    "    keyWord = []\n",
    "    for i,seg in enumerate(seg_list):\n",
    "        if len(keyWord) <=20:\n",
    "            keyWord.append((seg,ws[i]))\n",
    "    return keywords2hash(keyWord)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('淘宝', 0.5),\n",
       " ('开发者', 0.25),\n",
       " ('大会', 0.125),\n",
       " ('20191022', 0.0625),\n",
       " ('003', 0.0625)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content1 = \"淘宝开发者大会-20191022-003\"\n",
    "simhash1,keyWord1 = get_simhash_shorttext(content1)\n",
    "keyWord1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simhash(content):\n",
    "    for s in stops_title:\n",
    "        content = content.replace(s,\"\")\n",
    "    keyWord = jieba.analyse.textrank(sentence=content,\n",
    "                                     topK=20,\n",
    "                                     withWeight=True,\n",
    "                                     allowPOS=('ns', 'n', 'nz','nrt','vn', 'v','t','tg','tg','qt','mq','m','nr','nt',\"vn\",'q'))\n",
    "\n",
    "    if len(keyWord) == 0:\n",
    "        segs = jieba.lcut(content)\n",
    "        for seg in segs:\n",
    "            if len(keyWord) <=20:keyWord.append((seg,0.5))\n",
    "    return keywords2hash(keyWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0010101010001000111010001101110010001101001001100000010010011111'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# long text\n",
    "content = \"蒲公英-采用全新智能组网技术的路由器-20191022\"\n",
    "simhash,keyWord = get_simhash(content)\n",
    "simhash\n",
    "\n",
    "# '0010101010001010111011001100101110001001011101110001010000111101'\n",
    "# '0010101010001000111010001101110010001101001001100000010010011111'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0110101011001000111010001101110010001101001001100011010010011111'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# short text\n",
    "content = \"蒲公英-采用全新智能组网技术的路由器-20191022\"\n",
    "simhash,keyWord = get_simhash_shorttext(content)\n",
    "simhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('蒲公英', 0.5),\n",
       " ('采用', 0.5),\n",
       " ('智能', 0.5),\n",
       " ('组网', 0.5),\n",
       " ('技术', 0.5),\n",
       " ('路由器', 0.5),\n",
       " ('20191022', 0.5)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hammingDis(com,simhash):\n",
    "    \"\"\"\n",
    "    汉明距离\n",
    "    \"\"\"\n",
    "    t1 = '0b' + simhash\n",
    "    if isinstance(com, str):\n",
    "    # if type(com) == str:\n",
    "        t2 = '0b' + com\n",
    "    else:\n",
    "        t2 = '0b' + com.simhash\n",
    "    n = int(t1, 2) ^ int(t2, 2)\n",
    "    i = 0\n",
    "    while n:\n",
    "        n &= (n - 1)\n",
    "        i += 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content1 = \"淘宝开发者大会-20191022-001\"\n",
    "content2 = \"淘宝开发者大会-20191022-002\"\n",
    "simhash1,keyWord1 = get_simhash(content1)\n",
    "simhash2,keyWord2 = get_simhash_shorttext(content2)\n",
    "hammingDis(simhash1,simhash2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('淘宝', 0.5), ('开发者', 0.5), ('大会', 0.5), ('20191022', 0.5), ('001', 0.5)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyWord1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dup(coms,simhash,distance):\n",
    "    \"\"\"\n",
    "    dup 重复True\n",
    "    \"\"\"\n",
    "    if simhash in coms:\n",
    "        return True\n",
    "    \n",
    "    if distance != 0:\n",
    "        for com in coms:\n",
    "            if hammingDis(com,simhash) <= distance:\n",
    "                \"\"\"存在重复文件\"\"\"\n",
    "                return True\n",
    "    # coms.append(self.simhash)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coms = []\n",
    "coms.append(simhash)\n",
    "content = \"蒲公英-采用全新智能组网技术的路由器-2019-10-22\"\n",
    "simhash1,keyWord = get_simhash(content)\n",
    "# simhash1 = '0010101010001000111010001101110010001101001001100000010010011110'\n",
    "find_dup(coms, simhash1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "content1 = \"通信行业：地方政府助推5G建设，国务院大力发展智慧交通，持续看好5G板块－跟踪周报20190921\" + \"投资要点 \\n     策略观点:1、各省市陆续发布5G发展计划,深圳表示2020年8月底将累计建成5G基站4.5万个,5G基站建设密度全国领先。基于5G通讯技术推动商用产业发展,是目前北京、上海、广州、深圳一线城市及全国多地出台发展规划中的重中之重。我国网络建设及终端先于应用板块崛起,同时随着5G终端产业加速,5G终端板块投资机会逐步显现。2、国务院印发《交通强国建设纲要》,大力发展智慧交通,5G作为端-管-云之间的衔接桥梁,助力构建车路云协同的新型交通体系。3、个股方面建议关注两条主线:5G网络建设及5G应用及流量,从投资节奏来看,5G网络建设先行,流量及应用在网络建设之后,弹性更大。 \\n     行业动态及点评:各地陆续推出5G政策,统筹加快5G建设,提升5G产业链协同创新与集聚能力,助力经济高质量发展。国务院印发《交通强国建设纲要》,大力发展智慧交通,上下游企业资本信心更足,投入更加坚定。美的、中国电信、华为三方联合发布《5G+智能工厂网络及应用白皮书》,加快5G+工业互联网领域研究探索及项目落地。\\n      行业前瞻:2019亚太内容分发大会(2019年9月24日-25日)近期推荐组合:1、5G网络建设:中兴通讯(000063)、中国联通(600050)、世嘉科技(002796)、烽火通信(600498)、中际旭创(300308)。2、5G应用和流量:淳中科技(603516)、中科创达(300496)、二六三(002467)、中新赛克(002912)。中国铁塔(港股0788),网络规划设计板块相关个股也值得关注。\\n      建议关注组合:1、5G网络建设:中石科技(300684)、沪电股份(002463)、深南电路(002916)、新易盛(300502)、光迅科技(002281)、俊知集团(港股1300)。2、5G应用和流量:网宿科技(300017)、紫光股份(000938)、移为通信(300590)、会畅通讯(300578)、高新兴(300098)。3、云计算基础设施:光环新网(300383)、宝信软件(600845)、数据港(603881)。4、智慧交通:佳都科技(600728)、中科创达(300496)、四维图新(002405)、高新兴(300098)、宜通世纪(300310)。 \\n     市场回顾:近一周通信(申万)指数下跌1.72％；沪深300指数下跌0.92％；行业落后大盘0.80％。 \\n     风险提示:中美贸易摩擦缓和低于预期风险,行业增速放缓风险\\n \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0010101110100001111010111100101011000010001010100011101111110100'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simhash1,keyWord = get_simhash(content1)\n",
    "simhash1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "content2 = \"通信行业：地方政府助推5G建设，国务院大力发展智慧交通，持续看好5G...20190921\" + \"投资要点\\n     策略观点:1、各省市陆续发布5G发展计划,深圳表示2020年8月底将累计建成5G基站4.5万个,5G基站建设密度全国领先。基于5G通讯技术推动商用产业发展,是目前北京、上海、广州、深圳一线城市及全国多地出台发展规划中的重中之重。我国网络建设及终端先于应用板块崛起,同时随着5G终端产业加速,5G终端板块投资机会逐步显现。2、国务院印发《交通强国建设纲要》,大力发展智慧交通,5G作为端-管-云之间的衔接桥梁,助力构建车路云协同的新型交通体系。3、个股方面建议关注两条主线:5G网络建设及5G应用及流量,从投资节奏来看,5G网络建设先行,流量及应用在网络建设之后,弹性更大。\\n     行业动态及点评:各地陆续推出5G政策,统筹加快5G建设,提升5G产业链协同创新与集聚能力,助力经济高质量发展。国务院印发《交通强国建设纲要》,大力发展智慧交通,上下游企业资本信心更足,投入更加坚定。美的、中国电信、华为三方联合发布《5G+智能工厂网络及应用白皮书》,加快5G+工业互联网领域研究探索及项目落地。\\n     行业前瞻:2019亚太内容分发大会(2019年9月24日-25日)近期推荐组合:1、5G网络建设:中兴通讯(000063)、中国联通(600050)、世嘉科技(002796)、烽火通信(600498)、中际旭创(300308)。2、5G应用和流量:淳中科技(603516)、中科创达(300496)、二六三(002467)、中新赛克(002912)。中国铁塔(港股0788),网络规划设计板块相关个股也值得关注。\\n     建议关注组合:1、5G网络建设:中石科技(300684)、沪电股份(002463)、深南电路(002916)、新易盛(300502)、光迅科技(002281)、俊知集团(港股1300)。2、5G应用和流量:网宿科技(300017)、紫光股份(000938)、移为通信(300590)、会畅通讯(300578)、高新兴(300098)。3、云计算基础设施:光环新网(300383)、宝信软件(600845)、数据港(603881)。4、智慧交通:佳都科技(600728)、中科创达(300496)、四维图新(002405)、高新兴(300098)、宜通世纪(300310)。\\n     市场回顾:近一周通信(申万)指数下跌1.72％；沪深300指数下跌0.92％；行业落后大盘0.80％。\\n     风险提示:中美贸易摩擦缓和低于预期风险,行业增速放缓风险。\\n \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0010001110100001111010111100101011000010001010100011101111110100'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simhash2,keyWord = get_simhash(content2)\n",
    "simhash2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = \"0010001100000101111010111001111011010010001010100011110111100101\"\n",
    "s2 = \"0010001100000101111010110001111011010010001000101011100111100001\"\n",
    "hammingDis(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('路由器', 1.0),\n",
       " ('智能', 0.9904208972881985),\n",
       " ('技术', 0.9759882078368103),\n",
       " ('2019', 0.8464088764053259),\n",
       " ('采用', 0.8154838850302057),\n",
       " ('组网', 0.7878571377272482),\n",
       " ('10', 0.6611890618238442),\n",
       " ('22', 0.47140543597476264),\n",
       " ('蒲公英', 0.43795179996834765)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyWord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cpython-simhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from simhash import Simhash, SimhashIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how', 'owa', 'war', 'are', 'rey', 'eyo', 'you']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_features(s):\n",
    "    width = 3\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[^\\w]+', '', s)\n",
    "    return [s[i:i + width] for i in range(max(len(s) - width + 1, 1))]\n",
    "get_features('How are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SimhashIndex.bucket_size of <simhash.SimhashIndex object at 0x7f4f39e79550>>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    1: u'How are you? I Am fine. blar blar blar blar blar Thanks.',\n",
    "    2: u'How are you i am fine. blar blar blar blar blar than',\n",
    "    3: u'This is simhash test.',\n",
    "}\n",
    "objs = [(str(k), Simhash(get_features(v))) for k, v in data.items()]\n",
    "index = SimhashIndex(objs, k=3)  # `k` is the tolerance\n",
    "index.bucket_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1']\n"
     ]
    }
   ],
   "source": [
    "s1 = Simhash(get_features(u'How are you i am fine. blar blar blar blar blar thank'))\n",
    "print (index.get_near_dups(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7604580641891645972"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '4']\n"
     ]
    }
   ],
   "source": [
    "index.add('4', s1)\n",
    "print (index.get_near_dups(s1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### md5\n",
    "MD5即Message-Digest Algorithm 5（信息-摘要算法5）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6a360e983a12c112479ff97581f5723c'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "def get_md5(text):\n",
    "    m = hashlib.md5()\n",
    "    m.update(text.encode(encoding='UTF-8'))\n",
    "    return m.hexdigest()\n",
    "get_md5(\"我是一个词\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perceptual hash\n",
    "https://github.com/knjcode/imgdupes\n",
    "Perceptual hashes are a different concept compared to cryptographic hash functions like MD5 and SHA1.\n",
    "均值hash\n",
    "pHash\n",
    "https://www.cnblogs.com/faith0217/articles/4088386.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
