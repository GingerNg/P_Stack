{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.pytorch123.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([5, 3])\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[6.4460e-44, 1.6255e-43, 1.4153e-43],\n        [1.5414e-43, 1.6115e-43, 1.5554e-43],\n        [1.5975e-43, 5.6052e-44, 1.2752e-43],\n        [7.4269e-44, 6.4460e-44, 7.4269e-44],\n        [6.1657e-44, 4.4842e-44, 7.1466e-44]])"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x.size())\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[0.9143, 0.6363, 0.1054],\n        [0.7578, 0.6292, 0.4246],\n        [0.0159, 0.1496, 0.8645],\n        [0.1217, 0.0168, 0.7807],\n        [0.3239, 0.8942, 0.2614]])"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "torch.rand(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = torch.rand(5)\n",
    "torch.max(vec,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([5.5000, 3.0000, 9.0000])"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# 构造tensor\n",
    "x = torch.tensor([5.5, 3, 9.0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([3])"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([2, 3])"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "torch.tensor([[5.5, 3, 9.0],[6.0, 9.0, 5.0]]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8) # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3396a1b2b617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "x.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9882491827011108"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "torch.randn(1).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自动微分 auto_grad\n",
    "x --> y --> z --> out\n",
    "\n",
    "x.grad <-- backward -- out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[3., 3.],\n        [3., 3.]], grad_fn=<AddBackward0>)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<AddBackward0 at 0x7fedc7b5c1d0>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)  # requires_grad=True 来跟踪与它相关的计算\n",
    "y = x + 2\n",
    "print(y)\n",
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[27., 27.],\n        [27., 27.]], grad_fn=<MulBackward0>)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(27., grad_fn=<MeanBackward0>)"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.backward()\n",
    "# x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[9., 9.],\n        [9., 9.]])"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "out.backward(torch.tensor(2.0))\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        # x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.relu(self.conv1(x))  # torch.Size([1, 6, 28, 28]) :32-5+1\n",
    "        x = F.max_pool2d(x,(2,2))  # torch.Size([1, 6, 14, 14]) : 28/2\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Net(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([6, 1, 5, 5])"
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "source": [
    "params[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([1, 10])"
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32) # 32*32的输入\n",
    "out = net(input)\n",
    "out.size()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[[ 1.8508e-01,  1.1058e+00, -9.2410e-04,  ..., -9.2500e-01,\n           -1.6046e+00, -9.1191e-01],\n          [ 1.5073e+00,  7.2835e-01,  6.1985e-01,  ...,  1.8675e+00,\n            6.5220e-01,  1.0047e-01],\n          [-6.1039e-01, -1.2427e-01,  7.4717e-01,  ..., -2.0162e-01,\n           -5.1271e-01,  3.5293e-01],\n          ...,\n          [ 9.6776e-02, -1.5472e+00,  2.9112e-02,  ..., -1.6700e-01,\n            4.2853e-01, -3.3378e-01],\n          [-4.3333e-01, -5.7990e-02, -1.1173e+00,  ..., -3.1305e-02,\n            2.4031e-01, -2.6599e+00],\n          [ 1.9464e+00,  4.0971e-01,  1.2905e+00,  ..., -2.6088e+00,\n           -1.3387e-01,  9.0829e-01]]]])"
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "conv1.bias.grad before backward\nNone\nconv1.bias.grad after backward\ntensor([-0.0267, -0.0248,  0.0265, -0.0137,  0.0466,  0.0197])\n"
    }
   ],
   "source": [
    "net.zero_grad()  # 把所有参数梯度缓存器置零\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "out.backward(torch.randn(1, 10))\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(0.6880, grad_fn=<MseLossBackward>)"
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "# net = Net()\n",
    "output = net(input)\n",
    "target = torch.randn(10) # a dummy target, for example\n",
    "target = target.view(1, -1) # make it the same shape as output\n",
    "criterion = nn.MSELoss()  # 损失函数\n",
    "loss = criterion(output, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "conv1.bias.grad before backward\ntensor([0., 0., 0., 0., 0., 0.])\nconv1.bias.grad after backward\ntensor([-0.0060,  0.0002,  0.0031,  0.0009,  0.0030, -0.0011])\n"
    }
   ],
   "source": [
    "net.zero_grad() # zeroes the gradient buffers of all parameters\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "loss.backward() # 将损失反向传播\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数更新规则：weight = weight - learning_rate * gradient\n",
    "# 参数更新：torch.optim\n",
    "# 使用不同的更新规则，类似于 SGD, Nesterov-SGD, Adam, RMSProp, 等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "# in your training loop:\n",
    "optimizer.zero_grad() # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step() # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[0.5375, 0.1636, 0.2614],\n        [0.3691, 0.7959, 0.0344],\n        [0.4400, 0.2856, 0.5487],\n        [0.8095, 0.5042, 0.8373],\n        [0.2461, 0.1447, 0.1760]])"
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "dd = torch.rand(5, 3)\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[-0.4625, -0.8364, -0.7386],\n        [-0.6309, -0.2041, -0.9656],\n        [-0.5600, -0.7144, -0.4513],\n        [-0.1905, -0.4958, -0.1627],\n        [-0.7539, -0.8553, -0.8240]])"
     },
     "metadata": {},
     "execution_count": 136
    }
   ],
   "source": [
    "dd.sub_(torch.ones_like(dd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit3042f92b86ba43f28ff3e0f8edc65a4b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}