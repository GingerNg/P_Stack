{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "def split_train_test(X,Y):\n",
    "    \"\"\"\n",
    "    数据集切分\n",
    "    \"\"\"\n",
    "    sfolder = StratifiedKFold(n_splits = 3, random_state = 0, shuffle = False)\n",
    "\n",
    "    train_indexes = []\n",
    "    test_indexs = []\n",
    "    for train, test in sfolder.split(X, Y):\n",
    "        train_indexes.append(train)\n",
    "        test_indexs.append(test)\n",
    "\n",
    "    x_train = [X[i] for i in train_indexes[0]]\n",
    "    x_test = [X[i] for i in test_indexs[0]]\n",
    "\n",
    "    y_train =[Y[i] for i in train_indexes[0]]\n",
    "    y_test = [Y[i] for i in test_indexs[0]]\n",
    "    return x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_backgroud_eval(background_labels,eval_labels,all_pd):\n",
    "    \"\"\"\"\"\"\n",
    "    trainpds = []\n",
    "    testpds = []\n",
    "    for label in background_labels:\n",
    "        trainpds.append(all_pd[all_pd[\"Label\"]==label])\n",
    "    for label in eval_labels:\n",
    "        testpds.append(all_pd[all_pd[\"Label\"]==label])\n",
    "    train_pd = pd.concat(trainpds)\n",
    "    test_pd = pd.concat(testpds)\n",
    "    return train_pd,test_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pair_dataset(X,Y,f=None):\n",
    "    \"\"\"\n",
    "    X:data\n",
    "    Y:label\n",
    "    build pair of dataset  \n",
    "    构造数据集\n",
    "    \"\"\"\n",
    "    def convert(z):\n",
    "        if f:\n",
    "            z = f(z)\n",
    "        return z\n",
    "    lefts = []\n",
    "    rights = []\n",
    "    targets = []\n",
    "    for i in range(len(X)):\n",
    "        l = convert(X[i])\n",
    "        for j in range(i,len(X)):\n",
    "            r = convert(X[j])\n",
    "            lefts.append(l)\n",
    "            rights.append(r)\n",
    "            if Y[i] == Y[j]:\n",
    "                targets.append(1)\n",
    "            else:\n",
    "                targets.append(0) \n",
    "    data = {\"lefts\":np.array(lefts),\n",
    "           \"rights\":np.array(rights),\n",
    "           \"targets\":np.array(targets)}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def build_triplet_dataset(X,Y):\n",
    "    \"\"\"\n",
    "    X:data\n",
    "    Y:label\n",
    "    for triplet loss \n",
    "    构造数据集\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    classes = set(Y)\n",
    "    Y = np.array(Y)\n",
    "#     indices = [np.where(y_train == i)[0] for i in range(num_classes)]  # [[]] 每个类别的下标List\n",
    "    for l in classes:\n",
    "        p_indices = np.where(Y == l)[0] # [[]] 每个类别的下标List\n",
    "        n_indices = np.where(Y != l)[0]\n",
    "        for j in n_indices:\n",
    "            p_indexs = random.sample(list(p_indices),2)\n",
    "            pairs += [[X[p_indexs[0]],X[p_indexs[1]],X[j]]]\n",
    "    return np.array(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = [\"1\",\"2\",\"3\",\"11\",\"22\",\"33\",\"111\",\"222\",\"333\"]\n",
    "# Y = [0,0,0,1,1,1,2,2,2]\n",
    "# pairs = build_triplet_dataset(X,Y)\n",
    "# print(pairs)\n",
    "# pairs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def create_pairs(x, digit_indices, num_classes):\n",
    "    \"\"\"\n",
    "    创建正例和负例的Pairs\n",
    "    :param x: 数据\n",
    "    :param digit_indices: 不同类别的索引列表\n",
    "    :param num_classes: 类别\n",
    "    :return: Triplet Loss 的 Feed 数据\n",
    "    \"\"\"\n",
    "\n",
    "    pairs = []\n",
    "    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1  # 最小类别数\n",
    "    print(n)\n",
    "    for d in range(num_classes):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            inc = random.randrange(1, num_classes)\n",
    "            dn = (d + inc) % num_classes\n",
    "            z3 = digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2], x[z3]]]\n",
    "    return np.array(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = [[1,1],[1,2],[1,3],[1,4],\n",
    "#      [2,1],[2,2],[2,3],[2,4],\n",
    "#      [3,1],[3,2],[3,3],[3,4],\n",
    "#      [4,1],[4,2],[4,3],[4,4]]\n",
    "# indices = [[0,1,2,3],[4,5,6,7],[8,9,10,11],[12,13,14,15]]\n",
    "# num_classes = 4\n",
    "# create_pairs(x, indices, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data load and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取csv文本文件\n",
    "def filter_empty(n):\n",
    "    return n != \"\"\n",
    "\n",
    "def read_csvdata(data_path):\n",
    "    cnt = 0\n",
    "    rows = []\n",
    "    with open(data_path,mode='r',encoding='utf-8',newline='') as f:\n",
    "            #此处读取到的数据是将每行数据当做列表返回的\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                row = list(filter(filter_empty,row))\n",
    "                #此时输出的是一行行的列表\n",
    "                for r in row:\n",
    "                    rows.append((r,cnt))\n",
    "                cnt +=1\n",
    "    return rows\n",
    "\n",
    "# data_path = \"../Dataset/Contract/Synonyms/contract_lx.csv\"\n",
    "# lx = read_csvdata(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_load_data(data_path):\n",
    "    fr = open(data_path,'rb')  \n",
    "    data = pickle.load(fr) \n",
    "    return data\n",
    "# data_path = './data/traindata.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_dump_data(data,data_path):\n",
    "    #使用dump()将数据序列化到文件中  \n",
    "    fw = open(data_path,'wb')  \n",
    "    pickle.dump(data, fw) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = './data/testdata.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model load and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存\n",
    "from sklearn.externals import joblib\n",
    "# todump = {\n",
    "#     \"clf\":ovr_clf,\n",
    "#     \"tdidfvec\":tfidf_vectorizer,\n",
    "#     \"labelenc\":label_enc\n",
    "# }\n",
    "def sklearn_dump(todump,model_path):\n",
    "    joblib.dump(todump, \"contract_v1.m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
