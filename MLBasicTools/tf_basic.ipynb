{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>tensorflow基础<center>\n",
    "\n",
    "Tensorflow的设计理念称之为计算流图，在编写程序时，首先构筑整个系统的graph，代码并不会直接生效，这一点和python的其他数值计算库（如Numpy等）不同，graph为静态的，类似于docker中的镜像。然后，在实际的运行时，启动一个session，程序才会真正的运行。这样做的好处就是：避免反复地切换底层程序实际运行的上下文，tensorflow帮你优化整个系统的代码。\n",
    "\n",
    "\n",
    "tf.flags\n",
    "用于帮助我们添加命令行的可选参数\n",
    "FLAGS = tf.flags.FLAGS #FLAGS保存命令行参数的数据\n",
    "FLAGS._parse_flags() #将其解析成字典存储到FLAGS.__flags中\n",
    "\n",
    "\n",
    "tf.argmax(input, axis=None, name=None, dimension=None)\n",
    "此函数是对矩阵按行或列计算最大值\n",
    "\n",
    "\n",
    "- optimize_for_inference\n",
    "通过调用 optimize_for_inference 脚本，会自动删除模型中输入层和输出层之间所有不需要的节点。\n",
    "同时该脚本还做了一些其他优化以提高运行速度。例如它把显式批处理标准化运算跟卷积权重进行了合并，从而降低了计算量。\n",
    "\n",
    "tflearn是TensorFlow的高级封装\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.Session.run()\n",
    "\n",
    "run(    fetches,   feed_dict=None,    options=None,    run_metadata=None)\n",
    "\n",
    "tf.Session.run()函数返回值为fetches的执行结果。\n",
    "如果fetches是一个元素就返回一个值；\n",
    "若fetches是一个list，则返回list的值，\n",
    "若fetches是一个字典类型，则返回和fetches同keys的字典。\n",
    "feed_dict是一个字典，在字典中需要给出每一个用到的占位符的取值。\n",
    "\n",
    "\n",
    "##### tf.session 配置\n",
    "- log_device_placement=True : 是否打印设备分配日志\n",
    "- allow_soft_placement=True ： 如果你指定的设备不存在，允许TF自动分配设备\n",
    "- 使用allow_growth option，刚一开始分配少量的GPU容量，然后按需慢慢的增加，由于不会释放内存，所以会导致碎片\n",
    "\n",
    "##### 控制使用哪块GPU\n",
    "/ CUDA_VISIBLE_DEVICES=0  python your.py#使用GPU0\n",
    "~/ CUDA_VISIBLE_DEVICES=0,1 python your.py#使用GPU0,1\n",
    "\n",
    "- 注意单词不要打错\n",
    "- 或者在 程序开头\n",
    "- os.environ['CUDA_VISIBLE_DEVICES'] = '0' #使用 GPU 0\n",
    "- os.environ['CUDA_VISIBLE_DEVICES'] = '0,1' # 使用 GPU 0，1\n",
    "\n",
    "##### tf.app.run()\n",
    "\n",
    "如果你的代码中的入口函数不叫main()，而是一个其他名字的函数，如test()，则你应该这样写入口tf.app.run(test)\n",
    "如果你的代码中的入口函数叫main()，则你就可以把入口写成tf.app.run()\n",
    "\n",
    "\n",
    "\n",
    "### tf.Graph()\n",
    "tf.Graph() 默认执行\n",
    "graph定义了计算方式，是一些加减乘除等运算的组合，类似于一个函数。它本身不会进行任何计算，也不保存任何中间计算结果。\n",
    "session用来运行一个graph，或者运行graph的一部分。它类似于一个执行者，给graph灌入输入数据，得到输出，并保存中间的计算结果。\n",
    "同时它也给graph分配计算资源（如内存、显卡等）。\n",
    "op -- 操作\n",
    "graph就是由一系列op构成的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, array([1., 1.])]\n",
      "(40,)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(-1)\n",
    "y = tf.constant([-1 + 2j, -2])\n",
    "sess = tf.Session()\n",
    "# print(sess.run(tf.abs(x))) #1\n",
    "# print(sess.run(tf.abs(y))) #[ 2.23606798，2.        ]\n",
    "\n",
    "## 计算序列长度\n",
    "used = tf.sign(tf.abs(y))\n",
    "length = tf.reduce_sum(used)\n",
    "# length = tf.cast(length, tf.int32)\n",
    "print(sess.run([length,used]))\n",
    "\n",
    "pooled_outputs = []\n",
    "gmp1 = tf.Variable(tf.random_normal([2,10]))\n",
    "gmp2 = tf.Variable(tf.random_normal([2,10]))\n",
    "pooled_outputs.append(gmp1)\n",
    "pooled_outputs.append(gmp2)\n",
    "# Combine all the pooled features\n",
    "h_pool = tf.concat(pooled_outputs, 1)\n",
    "gmps = tf.reshape(h_pool, [-1, ])\n",
    "print(gmps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot \n",
    "\n",
    "- tf.sequence_mask\n",
    "- tf.boolean_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output of one-hot is :  [[1. 1. 0.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "res = tf.cast(tf.sequence_mask([2,3]), tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # sess.run(tf.global_variables_initializer())\n",
    "    output = sess.run(res)\n",
    "    print(\"output of one-hot is : \", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output of one-hot is :  [2. 3.]\n"
     ]
    }
   ],
   "source": [
    "res = tf.cast(tf.boolean_mask([2,3],mask=[1,3]),tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # sess.run(tf.global_variables_initializer())\n",
    "    output = sess.run(res)\n",
    "    print(\"output of one-hot is : \", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf读取数据\n",
    "tf.data API能够从不同的输入或文件格式中读取、预处理数据，并且对数据应用一些变换\n",
    "（例如，batching、shuffling、mapping function over the dataset），\n",
    "\n",
    "tf.data API 是旧的 feeding、QueueRunner的升级。\n",
    "基于C++的多线程及队列\n",
    "\n",
    "Feeding是数据输入效率最低的方式，应该只用于小数据集和调试（debugging）\n",
    "https://blog.csdn.net/u014061630/article/details/80712635\n",
    "\n",
    "\n",
    "[TensorFlow高效读取数据的方法](https://blog.csdn.net/u012759136/article/details/52232266)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-41dcf873af04>:11: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-8-41dcf873af04>:12: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n",
      "Tensor(\"ReaderReadV2:0\", shape=(), dtype=string) Tensor(\"ReaderReadV2:1\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "filename = './data/test.csv'\n",
    "file_queue = tf.train.string_input_producer([filename])  # 设置文件名队列，这样做能够批量读取文件夹中的文件\n",
    "reader = tf.TextLineReader(skip_header_lines=1)  # 使用tensorflow文本行阅读器，并且设置忽略第一行\n",
    "\n",
    "key, value = reader.read(file_queue)\n",
    "\n",
    "print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3]\n",
      "[2 3 1]\n",
      "[2 3]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "data = tf.constant([[1, 2, 1], [3, 1, 1]])\n",
    "# data = tf.Variable(tf.int32, [None, 10], name='input_x')\n",
    "print(sess.run(tf.shape(data)))\n",
    "d_1 = tf.expand_dims(data, 2)\n",
    "# d_1 = tf.expand_dims(d_1, 2)\n",
    "# d_1 = tf.expand_dims(d_1, -1)\n",
    "# d_1 = tf.expand_dims(d_1, -1)\n",
    "print(sess.run(tf.shape(d_1)))\n",
    "d_2 = d_1\n",
    "print(sess.run(tf.shape(tf.squeeze(d_1))))\n",
    "# print(sess.run(tf.shape(tf.squeeze(d_2, [2, 4]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### tf.range函数用来快速生成一个等差数列 \n",
    "    \n",
    "https://blog.csdn.net/lusing/article/details/80054716"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.  12.  23.  34.  45.  56.  67.  78.  89. 100.]\n",
      "[23. 34. 45. 56.]\n",
      "[1.        1.1111112 1.2222222 1.3333334 1.4444444 1.5555556 1.6666667\n",
      " 1.7777778 1.8888888 2.        2.        2.25      2.5       2.75\n",
      " 3.       ]\n",
      "[1 2]\n",
      "[2 2]\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "b11 = tf.range(1,100,1)  # 生成一个对象\n",
    "\n",
    "a5 = tf.linspace(1.0,100.0, 10)  # linspace生成浮点等差数组 从1.0至100.0 10个元素\n",
    "\n",
    "a6 = tf.slice(a5, [2], [4]) # 从index=2的元素开始，取4个元素\n",
    "\n",
    "a20 = tf.linspace(1.0,2.0,10)\n",
    "a21 = tf.linspace(2.0,3.0,5)\n",
    "# 连接操作\n",
    "a23 = tf.concat([a20,a21],-1)\n",
    "\n",
    "# 广播操作： 向量和标量中间进行运行（加减）\n",
    "b1 = tf.constant([1,2])\n",
    "b2 = tf.constant([2,1])\n",
    "\n",
    "\n",
    "# Hadamard积\n",
    "b3 = b1 * b2   # b3 = b1 * b2   # element-wise product)\n",
    "\n",
    "# 点积(dot product)\n",
    "# a31 = tf.constant(tf.reshape(a21,[2,1]))\n",
    "# a32 = tf.constant(tf.reshape(a21,[2,1]))\n",
    "# a31 = tf.matmul(a31,a32,transpose_a=True)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(b11)\n",
    "    print(sess.run(a5))\n",
    "    print(sess.run(a6))\n",
    "    print(sess.run(a23))\n",
    "    sess.run(a20)\n",
    "    sess.run(a21)\n",
    "    # print(sess.run(a23))\n",
    "    print(sess.run(b1))  # [1 2]\n",
    "\n",
    "    print(sess.run(b3))\n",
    "\n",
    "    # tensordot要求是浮点型矩阵\n",
    "    f01 = tf.constant([1, 1], dtype=tf.float32)\n",
    "    f02 = tf.constant([1, 2], dtype=tf.float32)\n",
    "    f11 = tf.constant(sess.run(tf.reshape(f01, [2, 1])))\n",
    "    f12 = tf.constant(sess.run(tf.reshape(f02, [2, 1])))\n",
    "    f13 = tf.tensordot(f11, f12, 2)\n",
    "    print(sess.run(f13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "3\n",
      "Tensor(\"Const_13:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Const_14:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"Const_15:0\", shape=(2, 2), dtype=string)\n",
      "Tensor(\"Const_16:0\", shape=(2, 3, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(0)\n",
    "xr = x.read_value()\n",
    "y = x.assign(3)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(x))\n",
    "    print(sess.run(xr))\n",
    "    print(sess.run(y))\n",
    "    \n",
    "# 创建一个整型常量，即 0 阶 Tensor\n",
    "t0 = tf.constant(3, dtype=tf.int32)\n",
    "# 创建一个浮点数的一维数组，即 1 阶 Tensor\n",
    "t1 = tf.constant([3., 4.1, 5.2], dtype=tf.float32)\n",
    "# 创建一个字符串的2x2数组，即 2 阶 Tensor\n",
    "t2 = tf.constant([['Apple', 'Orange'], ['Potato', 'Tomato']], dtype=tf.string)\n",
    "# 创建一个 2x3x1 数组，即 3 阶张量，数据类型默认为整型\n",
    "t3 = tf.constant([[[5], [6], [7]], [[4], [3], [2]]])\n",
    "\n",
    "# 打印上面创建的几个 Tensor\n",
    "print(t0)\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.nn.embedding_lookup（tensor, id）函数的用法主要是选取一个张量里面索引(id)对应的元素\n",
    "\n",
    "https://www.jianshu.com/p/abea0d9d2436"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_uniform_1:0\", shape=(10, 4), dtype=float32)\n",
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "(3, 2, 1)\n",
      "(3, 2)\n",
      "(3, 2, 2, 1)\n",
      "[[[[2]\n",
      "   [1]]\n",
      "\n",
      "  [[3]\n",
      "   [4]]]\n",
      "\n",
      "\n",
      " [[[3]\n",
      "   [4]]\n",
      "\n",
      "  [[2]\n",
      "   [1]]]\n",
      "\n",
      "\n",
      " [[[2]\n",
      "   [1]]\n",
      "\n",
      "  [[2]\n",
      "   [1]]]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "lk[0]也就是[0,1]对应着下面sess.run(lookup_data)的结果恰好是把data中的[[2],[1]],[[3],[4]]\n",
    "[\n",
    "    [\n",
    "        [[2][1]]\n",
    "        [[3][4]]\n",
    "    ]\n",
    "\n",
    "\n",
    "    [\n",
    "        [[3][4]]\n",
    "        [[2][1]]\n",
    "    ]\n",
    "\n",
    "\n",
    "    [\n",
    "        [[2][1]]\n",
    "        [[2][1]]\n",
    "    ]\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "# 返回10*4的矩阵，产生于low和high之间，产生的值是均匀分布的。\n",
    "w = tf.random_uniform([10, 4], -1.0, 1.0)\n",
    "print(w)   # 10*4\n",
    "\n",
    "print(tf.reduce_mean(w))\n",
    "\n",
    "# tf.reduce_mean 可跨越维度的计算张量各元素的平均值\n",
    "#\n",
    "# embedded_chars = tf.nn.embedding_lookup(w, input_x)\n",
    "\n",
    "data = np.array([[[2],[1]],[[3],[4]],[[6],[7]]])\n",
    "data = tf.convert_to_tensor(data)\n",
    "print(data.shape)  # 3*2*1\n",
    "lk = tf.convert_to_tensor(np.array([[0,1],[1,0],[0,0]]))\n",
    "print(lk.shape)\n",
    "lookup_data = tf.nn.embedding_lookup(data,lk)\n",
    "print(lookup_data.shape)\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(lookup_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'carry_gate_1:0' shape=(10, 1) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = tf.random_uniform([10, 1], -1.0, 1.0)\n",
    "C = tf.subtract(1.0, T, name=\"carry_gate\")  #　Returns x - y element-wise.\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'random_uniform_3:0' shape=(10, 1) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.random_normal    从正态分布中输出随机值。\n",
    "- tf.truncated_normal  从截断的正态分布中输出随机值;生成的值服从具有指定平均值和标准偏差的正态分布\n",
    "- tf.random_uniform 从均匀分布输出随机值。生成的值遵循该范围内的均匀分布 [minval, maxval)。下限minval包含在范围内，而maxval排除上限"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(10, 4, 5) dtype=float32_ref>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = 4   #  3*4 = 12\n",
    "embedding_dim = 5\n",
    "\n",
    "input = tf.Variable(tf.random_normal([10,seq_length,embedding_dim]))\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'split:0' shape=(10, 1, 5) dtype=float32>,\n",
       " <tf.Tensor 'split:1' shape=(10, 1, 5) dtype=float32>,\n",
       " <tf.Tensor 'split:2' shape=(10, 1, 5) dtype=float32>,\n",
       " <tf.Tensor 'split:3' shape=(10, 1, 5) dtype=float32>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_att = tf.split(input, seq_length, axis=1) # 提取张量的部分\n",
    "input_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_43:0' shape=(10, 4, 3, 5) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = []\n",
    "conttexts = []  # 10,4,3,5\n",
    "for index, x_index in enumerate(input_att):\n",
    "    tmp1 = []\n",
    "    tmp2 = []\n",
    "    # x_i = tf.reshape(x_index, [-1, embedding_dim])\n",
    "    # print(x_i)  # Tensor(\"split:0\", shape=(10, 1, 4), dtype=float32)  Tensor(\"Reshape:0\", shape=(10, 4), dtype=float32)\n",
    "    for indxe, x_indxe in enumerate(input_att):\n",
    "        # print(indxe)\n",
    "        if index != indxe:\n",
    "            # print(x_indxe.shape)\n",
    "            tmp1.append(tf.concat([x_index,x_indxe], axis=2))\n",
    "            tmp2.append(x_indxe)\n",
    "    tmp1 = tf.concat(tmp1, axis=1)\n",
    "    tmp2 = tf.concat(tmp2, axis=1)\n",
    "    # print(tmp1.shape)\n",
    "    outputs.append(tf.expand_dims(tmp1,1))\n",
    "    conttexts.append(tf.expand_dims(tmp2, 1))\n",
    "outputs = tf.concat(outputs, axis=1)\n",
    "conttexts = tf.concat(conttexts, axis=1)\n",
    "conttexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_5:0' shape=(10, 4, 3) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_dim = 3\n",
    "W = tf.Variable(tf.random_normal([embedding_dim*2, hidden_dim]))\n",
    "V = tf.Variable(tf.random_normal([hidden_dim,1]))\n",
    "outputs = tf.reshape(outputs,[-1,embedding_dim*2])\n",
    "WX = tf.matmul(outputs, W)\n",
    "# print(WX.shape) # (120, 3)\n",
    "\n",
    "VWX = tf.matmul(WX, V)\n",
    "# print(VWX.shape)\n",
    "VWX = tf.reshape(VWX,[-1,3])\n",
    "# print(VWX.shape)\n",
    "VWX = tf.exp(VWX)\n",
    "# print(VWX.shape)\n",
    "alpha_M = tf.reshape(tf.nn.softmax(VWX,1),[10,4,3])\n",
    "alpha_M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.tile\n",
    "\n",
    "tensorflow中的tile()函数是用来对张量(Tensor)进行扩展的，其特点是对当前张量内的数据进行一定规则的复制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Tile_1:0' shape=(10, 4, 3, 5) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_MM = tf.tile(tf.expand_dims(alpha_M,3),[1,1,1,embedding_dim])\n",
    "alpha_MM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.abs()就是求数值的绝对值，可以将多个数值传入list，统一求绝对值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[2.23606798 2.        ]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(-1)\n",
    "y = tf.constant([-1 + 2j, -2])\n",
    "sess = tf.Session()\n",
    "print(sess.run(tf.abs(x))) #1\n",
    "print(sess.run(tf.abs(y))) #[ 2.23606798，2.        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.gather \n",
    "用一个一维的索引数组，将张量中对应索引的向量提取出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5]\n",
      " [11 12 13 14 15]]\n",
      "[3 5 7 9]\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([[1,2,3,4,5], [6,7,8,9,10], [11,12,13,14,15]])\n",
    "index_a = tf.Variable([0,2])\n",
    " \n",
    "b = tf.Variable([1,2,3,4,5,6,7,8,9,10])\n",
    "index_b = tf.Variable([2,4,6,8])\n",
    " \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(tf.gather(a, index_a)))\n",
    "    print(sess.run(tf.gather(b, index_b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
